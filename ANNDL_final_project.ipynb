{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNDL Final Project: _Jeopardy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import (value, question, answer) three-ples from CSV.\n",
    "data = []\n",
    "with open(\"/Users/fiordali/Downloads/JEOPARDY_CSV.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        data.append(row[4:])\n",
    "\n",
    "random.shuffle(data) # Do I have to avoid shuffling the data/recreating the train and test data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177850\n"
     ]
    }
   ],
   "source": [
    "# We start with all 216,931 rows from the CSV file, which we will clean up.\n",
    "\n",
    "clean_data = []\n",
    "set_dollar_values = {\"$200\", \"$400\", \"$600\", \"$800\", \"$1000\",\n",
    "                     \"$1200\", \"$1600\", \"$2000\"}\n",
    "for item in data:\n",
    "    # Cut out rows that are Final Jeopardy (where dollar value = \"None\").\n",
    "    if item[0] != \"None\" and len(item[0]) > 0: \n",
    "        # Cut out rows that are Daily Double (where dollar value != one of the set dollar values; imperfect check)\n",
    "        if item[0] in set_dollar_values:\n",
    "            clean_data.append(item)\n",
    "\n",
    "# We now have 177,850 rows of data.\n",
    "\n",
    "# Convert dollar value strings into ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into two randomized groups: testing and training data.\n",
    "idx = len(data) // 2\n",
    "\n",
    "# Ideally would train on half the data points, but currently takes too long to run.\n",
    "train_set = data[:7500]\n",
    "test_set = data[7500:]\n",
    "\n",
    "# Remove dollar value and answer from training set.\n",
    "train_questions = []\n",
    "for item in train_set:\n",
    "    train_questions.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find length of longest training question by character.\n",
    "max_len = 0\n",
    "counter = 0\n",
    "\n",
    "for question in train_questions:\n",
    "    for letter in question:\n",
    "        counter += 1\n",
    "    if counter > max_len:\n",
    "        max_len = counter\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM on questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import requests as rq\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '<': 28, '=': 29, '>': 30, '?': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '[': 58, ']': 59, '_': 60, 'a': 61, 'b': 62, 'c': 63, 'd': 64, 'e': 65, 'f': 66, 'g': 67, 'h': 68, 'i': 69, 'j': 70, 'k': 71, 'l': 72, 'm': 73, 'n': 74, 'o': 75, 'p': 76, 'q': 77, 'r': 78, 's': 79, 't': 80, 'u': 81, 'v': 82, 'w': 83, 'x': 84, 'y': 85, 'z': 86, '¢': 87, '°': 88, 'é': 89, '–': 90, '’': 91, '“': 92, '”': 93, '…': 94}\n"
     ]
    }
   ],
   "source": [
    "# Q1: What is the purpose of this block? When is `char_indices` used? What about `indices_char`?\n",
    "chars = sorted(list(set(\"\".join(train_questions))))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: What is the purpose of this block? What do the `seqlen` and `step` parameters do?\n",
    "seqlen = max_len # Length in chars of longest question\n",
    "\n",
    "# Q3: What about this block? What is `x` and what is `y`? Why do they have this dimensionality?\n",
    "x = np.zeros((len(train_questions), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(train_questions), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, question in enumerate(train_questions):\n",
    "    # Q3a: What happens in this loop?\n",
    "    for t, (char_in, char_out) in enumerate(zip(question[:-1], question[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "# Q4: Here we build the model. What does the `return_sequences` argument do? Why the dense layer at the end?\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True)) # ret_seq = False because we want abstract feature vector as output\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 135s 18ms/step - loss: 0.4979 - categorical_crossentropy: 0.4979 - accuracy: 0.7320\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.3869 - categorical_crossentropy: 0.3869 - accuracy: 0.6764\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 133s 18ms/step - loss: 0.3424 - categorical_crossentropy: 0.3424 - accuracy: 0.8000\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.3204 - categorical_crossentropy: 0.3204 - accuracy: 0.7934\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.3052 - categorical_crossentropy: 0.3052 - accuracy: 0.7502\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.2932 - categorical_crossentropy: 0.2932 - accuracy: 0.7426\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 137s 18ms/step - loss: 0.2836 - categorical_crossentropy: 0.2836 - accuracy: 0.8940\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2766 - categorical_crossentropy: 0.2766 - accuracy: 0.9098\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2699 - categorical_crossentropy: 0.2699 - accuracy: 0.8963\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.2652 - categorical_crossentropy: 0.2652 - accuracy: 0.9133\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.2606 - categorical_crossentropy: 0.2606 - accuracy: 0.9130\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 149s 20ms/step - loss: 0.2571 - categorical_crossentropy: 0.2571 - accuracy: 0.9148\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.2539 - categorical_crossentropy: 0.2539 - accuracy: 0.9147\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 148s 20ms/step - loss: 0.2511 - categorical_crossentropy: 0.2511 - accuracy: 0.9111\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 138s 18ms/step - loss: 0.2488 - categorical_crossentropy: 0.2488 - accuracy: 0.9146\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 147s 20ms/step - loss: 0.2466 - categorical_crossentropy: 0.2466 - accuracy: 0.9140\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 153s 20ms/step - loss: 0.2446 - categorical_crossentropy: 0.2446 - accuracy: 0.9003\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 148s 20ms/step - loss: 0.2426 - categorical_crossentropy: 0.2426 - accuracy: 0.9008\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 169s 23ms/step - loss: 0.2411 - categorical_crossentropy: 0.2411 - accuracy: 0.9125\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 140s 19ms/step - loss: 0.2396 - categorical_crossentropy: 0.2396 - accuracy: 0.9138\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.2384 - categorical_crossentropy: 0.2384 - accuracy: 0.8979\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2369 - categorical_crossentropy: 0.2369 - accuracy: 0.8991\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 159s 21ms/step - loss: 0.2358 - categorical_crossentropy: 0.2358 - accuracy: 0.9044\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 152s 20ms/step - loss: 0.2349 - categorical_crossentropy: 0.2349 - accuracy: 0.8896\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 145s 19ms/step - loss: 0.2335 - categorical_crossentropy: 0.2335 - accuracy: 0.9003\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 146s 19ms/step - loss: 0.2328 - categorical_crossentropy: 0.2328 - accuracy: 0.9070\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 154s 21ms/step - loss: 0.2318 - categorical_crossentropy: 0.2318 - accuracy: 0.8907\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 164s 22ms/step - loss: 0.2310 - categorical_crossentropy: 0.2310 - accuracy: 0.8742\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 139s 19ms/step - loss: 0.2302 - categorical_crossentropy: 0.2302 - accuracy: 0.8925\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2295 - categorical_crossentropy: 0.2295 - accuracy: 0.8884\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 137s 18ms/step - loss: 0.2287 - categorical_crossentropy: 0.2287 - accuracy: 0.8864\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2287 - categorical_crossentropy: 0.2287 - accuracy: 0.8402\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2276 - categorical_crossentropy: 0.2276 - accuracy: 0.8157\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2271 - categorical_crossentropy: 0.2271 - accuracy: 0.8479\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 131s 18ms/step - loss: 0.2264 - categorical_crossentropy: 0.2264 - accuracy: 0.8559\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2259 - categorical_crossentropy: 0.2259 - accuracy: 0.8731\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2254 - categorical_crossentropy: 0.2254 - accuracy: 0.8788\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2253 - categorical_crossentropy: 0.2253 - accuracy: 0.8233\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 131s 18ms/step - loss: 0.2247 - categorical_crossentropy: 0.2247 - accuracy: 0.8621\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2715 - categorical_crossentropy: 0.2715 - accuracy: 0.4224\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.3900 - categorical_crossentropy: 0.3900 - accuracy: 0.2070\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 147s 20ms/step - loss: 0.4786 - categorical_crossentropy: 0.4786 - accuracy: 0.0839\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 129s 17ms/step - loss: 0.4187 - categorical_crossentropy: 0.4187 - accuracy: 0.0851\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.3160 - categorical_crossentropy: 0.3160 - accuracy: 0.1115\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.2873 - categorical_crossentropy: 0.2873 - accuracy: 0.1190\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.2834 - categorical_crossentropy: 0.2834 - accuracy: 0.1159\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.2799 - categorical_crossentropy: 0.2799 - accuracy: 0.1154\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 129s 17ms/step - loss: 0.2717 - categorical_crossentropy: 0.2717 - accuracy: 0.1214\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2527 - categorical_crossentropy: 0.2527 - accuracy: 0.4351\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2363 - categorical_crossentropy: 0.2363 - accuracy: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x170cb7ad0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FF on feature vectors from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature vectors for training questions.\n",
    "# The feature vectors will be the x_train data for the FF network.\n",
    "train_vectors = []\n",
    "\n",
    "for i in range(len(train_questions)):\n",
    "    x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(train_questions[i]):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    pred = model.predict(x_pred, verbose=0)\n",
    "    train_vectors.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data.\n",
    "y_train = []                 # This set will exclude Final Jeopardy rows\n",
    "\n",
    "for item in train_set:\n",
    "    if item[0] != \"None\" and len(item[0]) > 0:    # Final Jeopardy rows are distinguished by their dollar value = \"None\"\n",
    "        y_train.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data to train FF network.\n",
    "# (Feature vectors have same index as their original question and dollar value.)\n",
    "\n",
    "x_train = array(train_vectors)                     # Pass in feature vectors representing question text.\n",
    "y_train = array([row[0][1:] for row in y_train]) # Expect dollar value associated with each question as output.\n",
    "\n",
    "y_train_digits = []\n",
    "for i, item in enumerate(y_train):\n",
    "    dollar_value = y_train[i].replace(',', '')\n",
    "    y_train_digits.append(int(dollar_value))\n",
    "\n",
    "# print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train_digits[0]))\n",
    "print(y_train_digits[0] + y_train_digits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'e included an unflattering description of himself in one of \"The Canterbury Tales\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-c9c9514c6b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'e included an unflattering description of himself in one of \"The Canterbury Tales\"'"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "for i, value in enumerate(y_train):\n",
    "    level = y_train[i]\n",
    "    y_train[i] = int(y_train[i][1:])\n",
    "\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '$300'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-80eb12876821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0my_test_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# There are 10 question values ($200-$2000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# model = Sequential()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '$300'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "(x, y), _ = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape each image to 1dim vector. Effectively, reshape\n",
    "# `x_train` from (60000, 28, 28) to (60000, 28*28)\n",
    "x_train_mnist = x[:50000].reshape(-1, 28*28)\n",
    "x_test_mnist = x[50000:].reshape(-1, 28*28)\n",
    "\n",
    "# Reshape each 4d vector into a 2d vector\n",
    "# (7550, 1, 526, 95) -> (7550, 49970)\n",
    "x_train = x_train.reshape(-1,1*526*95)\n",
    "\n",
    "# Convert y_train from vector of labels to one-hot encoding vector\n",
    "print(y[:10])\n",
    "y = keras.utils.to_categorical(y, num_classes=10)\n",
    "print(y[:10])\n",
    "y_train_mnist = y[:50000]\n",
    "y_test_mnist = y[50000:]\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)     # There are 10 question values ($200-$2000)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, input_dim=526*95))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer=RMSprop(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           epochs=20,\n",
    "#           batch_size=128)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "* [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [Emma Boettcher Thesis](https://futurism.com/jeopardy-emma-boettcher-ai-james-holzhauer)\n",
    "* [A Gentle Introduction to LSTM Autoencoders](https://machinelearningmastery.com/lstm-autoencoders/)\n",
    "* [LSTM – nuggest for practical application](https://towardsdatascience.com/lstm-nuggets-for-practical-applications-5beef5252092)\n",
    "* [Understanding Stateful LSTM RNNs Python Keras](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)\n",
    "* [Reshape Input Data LSTMs](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/)\n",
    "* [How to use return_state](https://www.dlology.com/blog/how-to-use-return_state-or-return_sequences-in-keras/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
