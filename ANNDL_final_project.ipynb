{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNDL Final Project: _Jeopardy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "# from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import (value, question, answer) three-ples from CSV.\n",
    "data = []\n",
    "with open(\"/Users/fiordali/Downloads/JEOPARDY_CSV.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        data.append(row[4:])\n",
    "\n",
    "random.shuffle(data) # Do I have to avoid shuffling the data/recreating the train and test data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with all 216,931 rows from the CSV file, which we will clean up.\n",
    "clean_data = []\n",
    "\n",
    "# TODO: Use sklearn labelencoder instead\n",
    "dollar_values_map = {\"$200 \": 0, \"$400 \": 1, \"$600 \": 2, \"$800 \": 3, \"$1,000 \": 4,\n",
    "                     \"$1,200 \": 5, \"$1,600 \": 6, \"$2,000 \": 7} \n",
    "\n",
    "for row in data:\n",
    "    # Cut out rows that are Daily Double or Final Jeopardy (imperfect checking criteria)\n",
    "    value = row[0]\n",
    "    if value in dollar_values_map:\n",
    "        # Map dollar value string to corresponding 'index'.\n",
    "        row[0] = dollar_values_map[value]\n",
    "        clean_data.append(row)\n",
    "\n",
    "# We now have 182,217 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into two randomized groups: testing and training data.\n",
    "idx = len(clean_data) // 2\n",
    "\n",
    "# Ideally would split data in half, but currently takes too long to run.\n",
    "train_set = clean_data[:7500]\n",
    "test_set = clean_data[7500:15000]\n",
    "\n",
    "# Create sets of ONLY questions (remove dollar value and answer).\n",
    "all_questions = [row[1] for row in clean_data]\n",
    "lstm_train_questions = [row[1] for row in train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the characters that occur in the question text to indices.\n",
    "chars = sorted(list(set(\"\".join([row[1] for row in clean_data]))))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find length of longest training question by character.\n",
    "max_len = 0\n",
    "counter = 0\n",
    "\n",
    "for question in lstm_train_questions:\n",
    "    for letter in question:\n",
    "        counter += 1\n",
    "    if counter > max_len:\n",
    "        max_len = counter\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM on questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import requests as rq\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = max_len # Length in chars of longest question\n",
    "\n",
    "# For every question we indicate if a given character is present (in x) OR what the next character is (in y).\n",
    "x = np.zeros((len(lstm_train_questions), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(lstm_train_questions), seqlen, len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, question in enumerate(lstm_train_questions):\n",
    "    # Iterate over every question in the training data.\n",
    "    # For every question, pair character t with character t+1 to provide context.\n",
    "    for t, (char_in, char_out) in enumerate(zip(question[:-1], question[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True)) # ret_seq = False because we want abstract feature vector as output\n",
    "lstm_model.add(Dense(len(chars), activation='softmax'))                            # CUT THIS LAYER? Or is this the feature vector we pass to FF?\n",
    "\n",
    "lstm_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 191s 26ms/step - loss: 0.5068 - categorical_crossentropy: 0.5068 - accuracy: 0.7259\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 147s 20ms/step - loss: 0.4066 - categorical_crossentropy: 0.4066 - accuracy: 0.6365\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 149s 20ms/step - loss: 0.3553 - categorical_crossentropy: 0.3553 - accuracy: 0.7271\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 147s 20ms/step - loss: 0.3261 - categorical_crossentropy: 0.3261 - accuracy: 0.6917\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 148s 20ms/step - loss: 0.3082 - categorical_crossentropy: 0.3082 - accuracy: 0.8340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x147d3ffd0>"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FF on feature vectors from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 540, 126)\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "[[[1.6361788e-02 5.3902408e-03 7.7475873e-03 ... 3.1111655e-03\n",
      "   2.3663426e-03 1.4090101e-03]\n",
      "  [3.7408464e-02 3.4574748e-03 3.8847846e-03 ... 5.1791471e-04\n",
      "   5.0410780e-04 2.1345408e-04]\n",
      "  [1.6578005e-01 1.8813291e-03 2.9995050e-03 ... 3.0032401e-05\n",
      "   8.1760256e-05 8.3359910e-06]\n",
      "  ...\n",
      "  [2.0075856e-01 2.2773757e-03 1.1516644e-02 ... 2.2977754e-05\n",
      "   6.2739949e-05 3.1469513e-06]\n",
      "  [2.0075864e-01 2.2773754e-03 1.1516645e-02 ... 2.2977742e-05\n",
      "   6.2739971e-05 3.1469524e-06]\n",
      "  [2.0075862e-01 2.2773752e-03 1.1516644e-02 ... 2.2977740e-05\n",
      "   6.2739964e-05 3.1469522e-06]]]\n"
     ]
    }
   ],
   "source": [
    "# A quick way to check predictions. DELETE LATER.\n",
    "x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "print(x_pred.shape)\n",
    "pred = lstm_model.predict(x_pred, verbose=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature vectors for training questions.\n",
    "# The feature vectors will be the x_train data for the FF network.\n",
    "ff_train_vectors = []\n",
    "\n",
    "for i in range(len(lstm_train_questions)):\n",
    "    x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(lstm_train_questions[i]):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    pred = lstm_model.predict(x_pred, verbose=0)\n",
    "    ff_train_vectors.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.1266250e-02 3.2636736e-04 1.0913979e-03 ... 2.2489514e-05\n",
      "   2.4427823e-04 1.3034280e-05]\n",
      "  [5.6462851e-03 1.9178340e-04 4.1151870e-04 ... 9.2137880e-06\n",
      "   2.4401390e-05 5.3854428e-06]\n",
      "  [3.7833758e-02 3.6581009e-04 2.5705697e-03 ... 1.4364036e-05\n",
      "   2.7630402e-05 3.5621633e-06]\n",
      "  ...\n",
      "  [1.7368338e-01 1.0118251e-03 1.3046853e-02 ... 4.5242617e-05\n",
      "   1.3701910e-04 1.1066317e-05]\n",
      "  [1.7368335e-01 1.0118249e-03 1.3046857e-02 ... 4.5242610e-05\n",
      "   1.3701909e-04 1.1066325e-05]\n",
      "  [1.7368330e-01 1.0118247e-03 1.3046867e-02 ... 4.5242599e-05\n",
      "   1.3701904e-04 1.1066322e-05]]]\n"
     ]
    }
   ],
   "source": [
    "print(ff_train_vectors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data to train FF network.\n",
    "# (Feature vectors have same index as their original question and dollar value.)\n",
    "x = array(ff_train_vectors)                 # Pass in feature vectors representing question text.\n",
    "y = array([row[0] for row in train_set])    # Expect dollar value associated with each question as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "7500 7500\n",
      "7500\n",
      "4\n",
      "(7500, 1, 540, 126)\n"
     ]
    }
   ],
   "source": [
    "print(len(ff_train_vectors))\n",
    "print(len(x), len(y))\n",
    "print(len(lstm_train_questions))\n",
    "print(y[1])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape each 4d vector into a 2d vector\n",
    "# (7500, 1, 540, 126) -> (7500, 68040)\n",
    "x_train_ff = x.reshape(-1,1*540*126)\n",
    "\n",
    "# Reshape each 1d digit label into 2d one-hot encoding\n",
    "y_train_ff = keras.utils.to_categorical(y, num_classes=8)     # There are 8 dollar values (mapped as 0-7)\n",
    "\n",
    "ff_model = Sequential()\n",
    "\n",
    "# NO ACTIVATIONS IN OUTPUT (NO PREDICTION).\n",
    "# ff_model.add(Dense(512, input_dim=540*126, activation='relu'))\n",
    "# ff_model.add(Dropout(0.5))\n",
    "# ff_model.add(Dense(256, activation='relu'))\n",
    "# ff_model.add(Dropout(0.5))\n",
    "# ff_model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# ff_model.add(Dense(512, input_dim=540*126, activation='relu'))\n",
    "# ff_model.add(Dropout(0.2))\n",
    "# ff_model.add(Dense(8, activation='relu'))\n",
    "# ff_model.add(Dropout(0.2))\n",
    "\n",
    "# PREDICTION VECTOR FILLED WITH ACTIVATIONS!!! SOME (4/10) ACCURATE!\n",
    "ff_model.add(Dense(1024, input_dim=540*126, activation='relu'))\n",
    "ff_model.add(Dropout(0.5))\n",
    "ff_model.add(Dense(512, activation='sigmoid'))\n",
    "ff_model.add(Dropout(0.5))\n",
    "ff_model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "ff_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 110s 15ms/step - loss: 0.4019 - accuracy: 0.8616\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 86s 12ms/step - loss: 0.3731 - accuracy: 0.8746\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 75s 10ms/step - loss: 0.3691 - accuracy: 0.8749\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 77s 10ms/step - loss: 0.3678 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 76s 10ms/step - loss: 0.3657 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 84s 11ms/step - loss: 0.3647 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 72s 10ms/step - loss: 0.3636 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 87s 12ms/step - loss: 0.3628 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 76s 10ms/step - loss: 0.3620 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 70s 9ms/step - loss: 0.3609 - accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x146906690>"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model.fit(x_train_ff, y_train_ff,\n",
    "          epochs=10,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "for t, char in enumerate(test_set[300][1]):\n",
    "    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "lstm_pred = lstm_model.predict(x_pred, verbose=0)\n",
    "\n",
    "ff_pred = ff_model.predict(lstm_pred.reshape(-1,540*126))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the testing data for the FF network.\n",
    "x_test_ff = []  # Feature vectors.\n",
    "y_test_ff = []  # Corresponding dollar values.\n",
    "\n",
    "for i in range(7500):\n",
    "    x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(test_set[i][1]):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    pred = lstm_model.predict(x_pred, verbose=0)\n",
    "    x_test_ff.append(pred)\n",
    "    \n",
    "y_test_ff = [row[0] for row in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Row # 0\n",
      "test_set:\n",
      " [3, 'The Phoenicians used a liquid from several species of this gastropod to make Tyrian purple dye', 'Snail']\n",
      "[[0.19693382 0.271347   0.11098971 0.16939458 0.10414802 0.05318233\n",
      "  0.05226302 0.08221506]]\n",
      "---- Row # 1\n",
      "test_set:\n",
      " [6, 'Delacroix, like Byron, sided with this people\\'s fight to break free of Turkey, leading to his \"Massacre at Chios\"', 'Greeks']\n",
      "[[0.19340341 0.26690242 0.10847434 0.17032787 0.109807   0.05750459\n",
      "  0.05313412 0.0798901 ]]\n",
      "---- Row # 2\n",
      "test_set:\n",
      " [2, 'L. Frank Baum\\'s Oz books include these underground folk, spelled without the silent \"G\"', 'Nomes']\n",
      "[[0.19547854 0.2612157  0.11118241 0.16998594 0.10936431 0.05797143\n",
      "  0.05562843 0.08521166]]\n",
      "---- Row # 3\n",
      "test_set:\n",
      " [1, 'In \"Born Standing Up\", this \"wild & crazy guy\" recalled selling guidebooks at Disneyland at age 10', 'Sreve Martin']\n",
      "[[0.19551624 0.26480576 0.10893673 0.17145765 0.10830638 0.05544623\n",
      "  0.05270435 0.08154971]]\n",
      "---- Row # 4\n",
      "test_set:\n",
      " [3, \"Located just south of the Equator, it's South America's oldest capital\", 'Quito, Ecuador']\n",
      "[[0.19404438 0.26753926 0.10948665 0.17144565 0.10628951 0.0592825\n",
      "  0.05699182 0.08799834]]\n",
      "---- Row # 5\n",
      "test_set:\n",
      " [1, 'The title of this film is what a guard shouts as he leads Sean Penn to be executed', 'Dead Man Walking']\n",
      "[[0.19386901 0.26744452 0.10736528 0.17389975 0.10611297 0.06028973\n",
      "  0.05483263 0.08736379]]\n",
      "---- Row # 6\n",
      "test_set:\n",
      " [6, 'There was a certain glow in the air when Maria Sklodowska caught the eye of this French physicist in 1894', 'Pierre Curie']\n",
      "[[0.19181994 0.25940195 0.10891802 0.17868571 0.10591704 0.06069115\n",
      "  0.0561726  0.08864112]]\n",
      "---- Row # 7\n",
      "test_set:\n",
      " [2, 'He pummels Tommy Burns to become the first black heavyweight champ', '(Jack) Johnson']\n",
      "[[0.20218639 0.26995283 0.11092193 0.16482468 0.10838863 0.05239211\n",
      "  0.05036115 0.07733737]]\n",
      "---- Row # 8\n",
      "test_set:\n",
      " [1, 'Many have said that Margaret Mitchell based this character on her first husband, Red Upshaw', 'Rhett Butler']\n",
      "[[0.19836922 0.27302048 0.10947905 0.16708206 0.10334595 0.05294956\n",
      "  0.05147255 0.07964143]]\n",
      "---- Row # 9\n",
      "test_set:\n",
      " [1, 'This exiled Mexican general headed back home from Cuba in August 1846 to aid in the fight', 'Santa Anna']\n",
      "[[0.19298397 0.26469097 0.11216958 0.16851984 0.10909343 0.0547354\n",
      "  0.05414052 0.08565114]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    prediction = ff_model.predict((x_test_ff[i]).reshape(-1,540*126))\n",
    "    print(\"---- Row #\", i)\n",
    "    print(\"test_set:\\n\", test_set[i])\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = ff_model.evaluate(array(x_test_ff).reshape(-1,540*126), y_test_ff[0], batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "* [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [Emma Boettcher Thesis](https://futurism.com/jeopardy-emma-boettcher-ai-james-holzhauer)\n",
    "* [A Gentle Introduction to LSTM Autoencoders](https://machinelearningmastery.com/lstm-autoencoders/)\n",
    "* [LSTM – nuggest for practical application](https://towardsdatascience.com/lstm-nuggets-for-practical-applications-5beef5252092)\n",
    "* [Understanding Stateful LSTM RNNs Python Keras](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)\n",
    "* [Reshape Input Data LSTMs](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/)\n",
    "* [How to use return_state](https://www.dlology.com/blog/how-to-use-return_state-or-return_sequences-in-keras/)\n",
    "* [One-hot Encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)\n",
    "* [Dropout](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)\n",
    "* [ReLU](https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7)\n",
    "* [First Neural Network Project](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
