{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNDL Final Project: _Jeopardy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import (value, question, answer) three-ples from CSV.\n",
    "data = []\n",
    "with open(\"/Users/fiordali/Downloads/JEOPARDY_CSV.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        data.append(row[4:])\n",
    "\n",
    "random.shuffle(data) # Do I have to avoid shuffling the data/recreating the train and test data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into two randomized groups: testing and training data.\n",
    "idx = len(data) // 2\n",
    "\n",
    "train_set = data[:7500]\n",
    "test_set = data[idx:]\n",
    "\n",
    "# Remove dollar value and answer from training set.\n",
    "train_questions = []\n",
    "for item in train_set:\n",
    "    train_questions.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find length of longest training question by character.\n",
    "max_len = 0\n",
    "counter = 0\n",
    "\n",
    "for question in train_questions:\n",
    "    for letter in question:\n",
    "        counter += 1\n",
    "    if counter > max_len:\n",
    "        max_len = counter\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM on questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import requests as rq\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '<': 28, '=': 29, '>': 30, '?': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '[': 58, ']': 59, '_': 60, 'a': 61, 'b': 62, 'c': 63, 'd': 64, 'e': 65, 'f': 66, 'g': 67, 'h': 68, 'i': 69, 'j': 70, 'k': 71, 'l': 72, 'm': 73, 'n': 74, 'o': 75, 'p': 76, 'q': 77, 'r': 78, 's': 79, 't': 80, 'u': 81, 'v': 82, 'w': 83, 'x': 84, 'y': 85, 'z': 86, '¢': 87, '°': 88, 'é': 89, '–': 90, '’': 91, '“': 92, '”': 93, '…': 94}\n"
     ]
    }
   ],
   "source": [
    "# Q1: What is the purpose of this block? When is `char_indices` used? What about `indices_char`?\n",
    "chars = sorted(list(set(\"\".join(train_questions))))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: What is the purpose of this block? What do the `seqlen` and `step` parameters do?\n",
    "seqlen = max_len # Length in chars of longest question\n",
    "\n",
    "# Q3: What about this block? What is `x` and what is `y`? Why do they have this dimensionality?\n",
    "x = np.zeros((len(train_questions), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(train_questions), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, question in enumerate(train_questions):\n",
    "    # Q3a: What happens in this loop?\n",
    "    for t, (char_in, char_out) in enumerate(zip(question[:-1], question[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "\n",
    "# Q4: Here we build the model. What does the `return_sequences` argument do? Why the dense layer at the end?\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True)) # ret_seq = False because we want abstract feature vector as output\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 135s 18ms/step - loss: 0.4979 - categorical_crossentropy: 0.4979 - accuracy: 0.7320\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.3869 - categorical_crossentropy: 0.3869 - accuracy: 0.6764\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 133s 18ms/step - loss: 0.3424 - categorical_crossentropy: 0.3424 - accuracy: 0.8000\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.3204 - categorical_crossentropy: 0.3204 - accuracy: 0.7934\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.3052 - categorical_crossentropy: 0.3052 - accuracy: 0.7502\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.2932 - categorical_crossentropy: 0.2932 - accuracy: 0.7426\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 137s 18ms/step - loss: 0.2836 - categorical_crossentropy: 0.2836 - accuracy: 0.8940\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2766 - categorical_crossentropy: 0.2766 - accuracy: 0.9098\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2699 - categorical_crossentropy: 0.2699 - accuracy: 0.8963\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 132s 18ms/step - loss: 0.2652 - categorical_crossentropy: 0.2652 - accuracy: 0.9133\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.2606 - categorical_crossentropy: 0.2606 - accuracy: 0.9130\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 149s 20ms/step - loss: 0.2571 - categorical_crossentropy: 0.2571 - accuracy: 0.9148\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.2539 - categorical_crossentropy: 0.2539 - accuracy: 0.9147\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 148s 20ms/step - loss: 0.2511 - categorical_crossentropy: 0.2511 - accuracy: 0.9111\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 138s 18ms/step - loss: 0.2488 - categorical_crossentropy: 0.2488 - accuracy: 0.9146\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 147s 20ms/step - loss: 0.2466 - categorical_crossentropy: 0.2466 - accuracy: 0.9140\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 153s 20ms/step - loss: 0.2446 - categorical_crossentropy: 0.2446 - accuracy: 0.9003\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 148s 20ms/step - loss: 0.2426 - categorical_crossentropy: 0.2426 - accuracy: 0.9008\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 169s 23ms/step - loss: 0.2411 - categorical_crossentropy: 0.2411 - accuracy: 0.9125\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 140s 19ms/step - loss: 0.2396 - categorical_crossentropy: 0.2396 - accuracy: 0.9138\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 136s 18ms/step - loss: 0.2384 - categorical_crossentropy: 0.2384 - accuracy: 0.8979\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2369 - categorical_crossentropy: 0.2369 - accuracy: 0.8991\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 159s 21ms/step - loss: 0.2358 - categorical_crossentropy: 0.2358 - accuracy: 0.9044\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 152s 20ms/step - loss: 0.2349 - categorical_crossentropy: 0.2349 - accuracy: 0.8896\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 145s 19ms/step - loss: 0.2335 - categorical_crossentropy: 0.2335 - accuracy: 0.9003\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 146s 19ms/step - loss: 0.2328 - categorical_crossentropy: 0.2328 - accuracy: 0.9070\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 154s 21ms/step - loss: 0.2318 - categorical_crossentropy: 0.2318 - accuracy: 0.8907\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 164s 22ms/step - loss: 0.2310 - categorical_crossentropy: 0.2310 - accuracy: 0.8742\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 139s 19ms/step - loss: 0.2302 - categorical_crossentropy: 0.2302 - accuracy: 0.8925\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2295 - categorical_crossentropy: 0.2295 - accuracy: 0.8884\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 137s 18ms/step - loss: 0.2287 - categorical_crossentropy: 0.2287 - accuracy: 0.8864\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2287 - categorical_crossentropy: 0.2287 - accuracy: 0.8402\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2276 - categorical_crossentropy: 0.2276 - accuracy: 0.8157\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2271 - categorical_crossentropy: 0.2271 - accuracy: 0.8479\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 131s 18ms/step - loss: 0.2264 - categorical_crossentropy: 0.2264 - accuracy: 0.8559\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2259 - categorical_crossentropy: 0.2259 - accuracy: 0.8731\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2254 - categorical_crossentropy: 0.2254 - accuracy: 0.8788\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 131s 17ms/step - loss: 0.2253 - categorical_crossentropy: 0.2253 - accuracy: 0.8233\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 131s 18ms/step - loss: 0.2247 - categorical_crossentropy: 0.2247 - accuracy: 0.8621\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2715 - categorical_crossentropy: 0.2715 - accuracy: 0.4224\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.3900 - categorical_crossentropy: 0.3900 - accuracy: 0.2070\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 147s 20ms/step - loss: 0.4786 - categorical_crossentropy: 0.4786 - accuracy: 0.0839\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 129s 17ms/step - loss: 0.4187 - categorical_crossentropy: 0.4187 - accuracy: 0.0851\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.3160 - categorical_crossentropy: 0.3160 - accuracy: 0.1115\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.2873 - categorical_crossentropy: 0.2873 - accuracy: 0.1190\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.2834 - categorical_crossentropy: 0.2834 - accuracy: 0.1159\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 128s 17ms/step - loss: 0.2799 - categorical_crossentropy: 0.2799 - accuracy: 0.1154\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 129s 17ms/step - loss: 0.2717 - categorical_crossentropy: 0.2717 - accuracy: 0.1214\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 130s 17ms/step - loss: 0.2527 - categorical_crossentropy: 0.2527 - accuracy: 0.4351\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 141s 19ms/step - loss: 0.2363 - categorical_crossentropy: 0.2363 - accuracy: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x170cb7ad0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "#           callbacks=[print_callback],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FF on feature vectors from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature vectors for training questions.\n",
    "# The feature vectors will be the x_train data for the FF network.\n",
    "train_vectors = []\n",
    "\n",
    "for i in range(len(train_questions)):\n",
    "    x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(train_questions[i]):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    pred = model.predict(x_pred, verbose=0)\n",
    "    train_vectors.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair feature vectors with their question's associated dollar value.\n",
    "# (Feature vectors have same index as their original question and dollar value.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "* [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [Emma Boettcher Thesis](https://futurism.com/jeopardy-emma-boettcher-ai-james-holzhauer)\n",
    "* [A Gentle Introduction to LSTM Autoencoders](https://machinelearningmastery.com/lstm-autoencoders/)\n",
    "* [LSTM – nuggest for practical application](https://towardsdatascience.com/lstm-nuggets-for-practical-applications-5beef5252092)\n",
    "* [Understanding Stateful LSTM RNNs Python Keras](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)\n",
    "* [Reshape Input Data LSTMs](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/)\n",
    "* [How to use return_state](https://www.dlology.com/blog/how-to-use-return_state-or-return_sequences-in-keras/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
